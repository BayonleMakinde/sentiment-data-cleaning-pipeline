ğŸŒ¸ **Codveda â€“ Task 1 | Python Data Analysis Intern**

**Social Media Sentiments: From Raw Text to Actionable Insights â€” A Data Story**

ğŸ“Š **Python | Pandas | Data Preprocessing**

---
### ğŸ“Œ Overview

Hereâ€™s the summary of the project: I used Pandas to clean 700+ sentiment records. I handled nulls/duplicates, normalized text for consistency, and transformed timestamps into datetime objects to engineer an 'Hour' feature for tracking peak engagement.

Instead of working with raw, noisy data, this script establishes a full analytical pipeline by connecting:
* User sentiment patterns
* Engagement metrics (Likes & Retweets)
* Temporal activity trends
* Global platform distribution

---
### âš™ï¸ Technical Workflow

1. **Data Auditing**: Initial inspection of 15 columns using `.info()` and `.isnull()`.
2. **Integrity Cleaning**: Automated removal of null values and duplicate records.
3. **Text Normalization**: Standardizing 'Sentiment' labels and converting 'Text' to lowercase.
4. **Time-Series Preparation**: Converting string timestamps to `datetime` objects.
5. **Feature Engineering**: Extracting 'Hour' from timestamps for engagement analysis.

---
### ğŸ› ï¸ Tools & Libraries
* **Language:** Python 3.13
* **Libraries:** Pandas, NumPy
* **Environment:** Jupyter Notebook / VS Cod

  ---
  ![Alt Text](Screenshots/cleaned-data.png)
